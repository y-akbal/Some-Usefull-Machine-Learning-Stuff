{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "042d57ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19441b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ebd9ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "818a7fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e79b3c9730>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAANR0lEQVR4nO3dX4xc5X3G8efxsjbBCYrX1M7GOEAJlkor1VSLqeJAqUgRQakMSoJiKakroToXsRSkXEBpq1DloiRqQqM2QnLAjVMloFQJwhckxVgoCCVyvBAX2zUthBowdr1OncgmmPWf/fViD9Vids6M55yZM97f9yONZva8c+Y8GvnxmZ13Zl9HhADMffOaDgCgPyg7kARlB5Kg7EASlB1I4rx+Hmy+F8T5WtjPQwKpvKnf6ERMeraxSmW3fZOkr0sakvRARNxbdv/ztVDX+IYqhwRQYntsaznW9ct420OSviHpo5KulLTW9pXdPh6A3qryO/sqSS9GxEsRcULSw5LW1BMLQN2qlH2ZpFdn/Ly/2PY2ttfbHrc9flKTFQ4HoIoqZZ/tTYB3fPY2IjZGxFhEjA1rQYXDAaiiStn3S1o+4+eLJR2oFgdAr1Qp+w5JV9i+zPZ8SZ+StKWeWADq1vXUW0Scsr1B0r9peuptU0TsqS0ZgFpVmmePiMckPVZTFgA9xMdlgSQoO5AEZQeSoOxAEpQdSIKyA0lQdiAJyg4kQdmBJCg7kARlB5Kg7EASlB1IgrIDSVB2IAnKDiRB2YEkKDuQBGUHkqDsQBKUHUiCsgNJUHYgCcoOJEHZgSQoO5AEZQeSoOxAEpQdSKLSKq7AIPvNJ65pOfblr9xfuu+Xbvuz0vEY391VpiZVKrvtfZKOSTot6VREjNURCkD96jiz/3FE/LKGxwHQQ/zODiRRtewh6XHbz9heP9sdbK+3PW57/KQmKx4OQLeqvoxfHREHbC+RtNX28xHx1Mw7RMRGSRsl6UKPRMXjAehSpTN7RBworickPSJpVR2hANSv67LbXmj7PW/dlnSjpHNvPgJIosrL+KWSHrH91uN8NyJ+VEuqHji+pvxFx/HFQ6XjI5t+Wmcc9MHEWOtz2Zf2/WkfkwyGrsseES9J+v0aswDoIabegCQoO5AEZQeSoOxAEpQdSCLNV1wPXFf+/9oFl/+6/AE21ZcFNZlXPl0aHzjecuyGJc+X7rvNH+oq0iDjzA4kQdmBJCg7kARlB5Kg7EASlB1IgrIDSaSZZ//bj/1r6fiX997YpySoy9Dll5SOP/9HrT8csfJnny7d9/07dnWVaZBxZgeSoOxAEpQdSIKyA0lQdiAJyg4kQdmBJNLMsw/7VNMRULPzHnij632P/+LCGpOcGzizA0lQdiAJyg4kQdmBJCg7kARlB5Kg7EASc2aeferDK0vHrz3/6f4EQd9cuvB/u953+ROna0xybmh7Zre9yfaE7d0zto3Y3mr7heJ6UW9jAqiqk5fx35J00xnb7pK0LSKukLSt+BnAAGtb9oh4StKRMzavkbS5uL1Z0i31xgJQt27foFsaEQclqbhe0uqOttfbHrc9flKTXR4OQFU9fzc+IjZGxFhEjA1rQa8PB6CFbst+yPaoJBXXE/VFAtAL3ZZ9i6R1xe11kh6tJw6AXmk7z277IUnXS7rI9n5JX5R0r6Tv2b5d0iuSPtnLkJ14+WPvKh1fMnRBn5KgLudd+oHS8U+MbOn6sd/1378qHZ+Ls/Btyx4Ra1sM3VBzFgA9xMdlgSQoO5AEZQeSoOxAEpQdSGLOfMX1vA8eq7T/m8+/t54gqM2r/7CwdHz1gqnS8QePXtx68NdHu4l0TuPMDiRB2YEkKDuQBGUHkqDsQBKUHUiCsgNJzJl59qqWjJfP2WJ2QxctLh0/9PEVLcdGbttfuu+PVzzY5ujnl47e/41bWo4tOfSTNo8993BmB5Kg7EASlB1IgrIDSVB2IAnKDiRB2YEkmGcvHB8p/3+v/JvV1Uxde1XpeAy5dPzVj7ReaefE+0+W7jtvfvkfTX782n8sHR8uj6b/Od0629+8dGvpvkemyj/7cMG88uxLt7f+GwdRuufcxJkdSIKyA0lQdiAJyg4kQdmBJCg7kARlB5KYM/Psk28Ol45PtZlZ/ee77ysd37Jh5dlG6tidix8oHZ+n8sns43Gi5diB0+Vz0f90+PrS8Y88cUfp+Ht/Pr90fPTxQy3H/HL599kP7y1fhnvpUPlnCGLHrtLxbNqe2W1vsj1he/eMbffYfs32zuJyc29jAqiqk5fx35J00yzb74uIlcXlsXpjAahb27JHxFOSjvQhC4AeqvIG3QbbzxUv8xe1upPt9bbHbY+f1GSFwwGootuy3y/pckkrJR2U9NVWd4yIjRExFhFjw2r9pQgAvdVV2SPiUEScjogpSd+UtKreWADq1lXZbY/O+PFWSbtb3RfAYGg7z277IUnXS7rI9n5JX5R0ve2Vmv5a8D5Jn+1dxM588NM/Lx3/3b/bUDq+/OrX6oxzVp6caP231SXp8A9L1hmXtHhP6/nm+T/a0ebo5XPVKzTeZv9yZbP8r935odJ9r17w09Lxh19f1kWivNqWPSLWzrK53V/vBzBg+LgskARlB5Kg7EASlB1IgrIDScyZr7i2c9lflk/jDLJRvdJ0hJ644LrDlfb/6yc/Xjq+Qj+r9PhzDWd2IAnKDiRB2YEkKDuQBGUHkqDsQBKUHUgizTw75p5LHs248HL3OLMDSVB2IAnKDiRB2YEkKDuQBGUHkqDsQBKUHUiCsgNJUHYgCcoOJEHZgSQoO5AEZQeSoOxAEnyfHQNryOXnol+tGC4df98P60xz7mt7Zre93PaTtvfa3mP788X2Edtbbb9QXC/qfVwA3erkZfwpSV+IiN+R9IeSPmf7Skl3SdoWEVdI2lb8DGBAtS17RByMiGeL28ck7ZW0TNIaSZuLu22WdEuPMgKowVm9QWf7UklXSdouaWlEHJSm/0OQtKTFPuttj9seP6nJinEBdKvjstt+t6TvS7ojIo52ul9EbIyIsYgYG9aCbjICqEFHZbc9rOmifyciflBsPmR7tBgflTTRm4gA6tDJu/GW9KCkvRHxtRlDWyStK26vk/Ro/fGQ2emYKr1onsoveJtO5tlXS/qMpF22dxbb7pZ0r6Tv2b5d0iuSPtmThABq0bbsEfG0JLcYvqHeOAB6hRc7QBKUHUiCsgNJUHYgCcoOJMFXXHHOeuPqN5qOcE7hzA4kQdmBJCg7kARlB5Kg7EASlB1IgrIDSTDPjoHV7k9J4+zwbAJJUHYgCcoOJEHZgSQoO5AEZQeSoOxAEsyzozGTT/xW6fjplVN9SpIDZ3YgCcoOJEHZgSQoO5AEZQeSoOxAEpQdSMIRUX4He7mkb0t6n6QpSRsj4uu275H0F5IOF3e9OyIeK3usCz0S15iFX4Fe2R7bdDSOzLrqcicfqjkl6QsR8azt90h6xvbWYuy+iPj7uoIC6J1O1mc/KOlgcfuY7b2SlvU6GIB6ndXv7LYvlXSVpO3Fpg22n7O9yfaiFvustz1ue/ykJqulBdC1jstu+92Svi/pjog4Kul+SZdLWqnpM/9XZ9svIjZGxFhEjA1rQfXEALrSUdltD2u66N+JiB9IUkQciojTETEl6ZuSVvUuJoCq2pbdtiU9KGlvRHxtxvbRGXe7VdLu+uMBqEsn78avlvQZSbts7yy23S1pre2VkkLSPkmf7UE+ADXp5N34pyXNNm9XOqcOYLDwCTogCcoOJEHZgSQoO5AEZQeSoOxAEpQdSIKyA0lQdiAJyg4kQdmBJCg7kARlB5Kg7EASbf+UdK0Hsw9LennGposk/bJvAc7OoGYb1FwS2bpVZ7ZLImLWtbD7WvZ3HNwej4ixxgKUGNRsg5pLIlu3+pWNl/FAEpQdSKLpsm9s+PhlBjXboOaSyNatvmRr9Hd2AP3T9JkdQJ9QdiCJRspu+ybb/2n7Rdt3NZGhFdv7bO+yvdP2eMNZNtmesL17xrYR21ttv1Bcz7rGXkPZ7rH9WvHc7bR9c0PZltt+0vZe23tsf77Y3uhzV5KrL89b339ntz0k6b8k/Ymk/ZJ2SFobEf/R1yAt2N4naSwiGv8Ahu3rJL0u6dsR8XvFtq9IOhIR9xb/US6KiDsHJNs9kl5vehnvYrWi0ZnLjEu6RdKfq8HnriTXberD89bEmX2VpBcj4qWIOCHpYUlrGsgx8CLiKUlHzti8RtLm4vZmTf9j6bsW2QZCRByMiGeL28ckvbXMeKPPXUmuvmii7MskvTrj5/0arPXeQ9Ljtp+xvb7pMLNYGhEHpel/PJKWNJznTG2X8e6nM5YZH5jnrpvlz6tqouyzLSU1SPN/qyPiDyR9VNLniper6ExHy3j3yyzLjA+Ebpc/r6qJsu+XtHzGzxdLOtBAjllFxIHiekLSIxq8pagPvbWCbnE90XCe/zdIy3jPtsy4BuC5a3L58ybKvkPSFbYvsz1f0qckbWkgxzvYXli8cSLbCyXdqMFbinqLpHXF7XWSHm0wy9sMyjLerZYZV8PPXePLn0dE3y+Sbtb0O/K/kPRXTWRokeu3Jf17cdnTdDZJD2n6Zd1JTb8iul3SYknbJL1QXI8MULZ/kbRL0nOaLtZoQ9k+rOlfDZ+TtLO43Nz0c1eSqy/PGx+XBZLgE3RAEpQdSIKyA0lQdiAJyg4kQdmBJCg7kMT/AT3d83+88ik1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d589e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The number of classes, this is really important\n",
    "CLS = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e84cdf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a86948d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0  #### very important trick---normalize your inputs!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0f192141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Input\n",
    "from tensorflow.keras.activations import softmax, relu\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Sequential, Model  ### Model is used for functional api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "461073f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, sparse_categorical_crossentropy, categorical_crossentropy\n",
    "from tensorflow.keras.metrics import Accuracy, Recall, FalsePositives, FalseNegatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f84c14c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Dropout(0.4),\n",
    "    Dense(200, activation = \"relu\", ),\n",
    "    Dropout(0.2),\n",
    "    Dense(15, activation = \"relu\"),\n",
    "    Dense(CLS, activation = \"softmax\") ###CLs = 10\n",
    "])   #####This way of creating models limits you to toy models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7cdddc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = RMSprop(), loss = sparse_categorical_crossentropy, metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7f2c81c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.8974 - accuracy: 0.7111 - val_loss: 0.3412 - val_accuracy: 0.9070\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.5325 - accuracy: 0.8323 - val_loss: 0.2767 - val_accuracy: 0.9191\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 4s 5ms/step - loss: 0.4763 - accuracy: 0.8508 - val_loss: 0.2518 - val_accuracy: 0.9246\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.4492 - accuracy: 0.8595 - val_loss: 0.2389 - val_accuracy: 0.9301\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.4364 - accuracy: 0.8629 - val_loss: 0.2304 - val_accuracy: 0.9337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e79f1d0a30>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,  batch_size = 64, epochs = 5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "06b96814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "630fb632",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = Input(shape = (28,28))\n",
    "f = Flatten()(I)\n",
    "y = Dense(100, \"relu\")(f)\n",
    "x = Dropout(0.2)(y)\n",
    "x = Dense(150, \"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(100, \"relu\")(x)\n",
    "x += y\n",
    "x = Dense(10, \"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cb724f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(I, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e065da39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7b443ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.2863 - accuracy: 0.9144 - val_loss: 0.1462 - val_accuracy: 0.9516\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 0.1363 - accuracy: 0.9596 - val_loss: 0.1021 - val_accuracy: 0.9689\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.1044 - accuracy: 0.9689 - val_loss: 0.0849 - val_accuracy: 0.9752\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.0856 - accuracy: 0.9736 - val_loss: 0.0825 - val_accuracy: 0.9766\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 5s 5ms/step - loss: 0.0758 - accuracy: 0.9770 - val_loss: 0.0840 - val_accuracy: 0.9761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7a3a428e0>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = RMSprop(), loss = sparse_categorical_crossentropy, metrics = [\"accuracy\"])\n",
    "model.fit(X_train, y_train,  batch_size = 64, epochs = 5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4315e151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 28, 28)]     0           []                               \n",
      "                                                                                                  \n",
      " flatten_12 (Flatten)           (None, 784)          0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_42 (Dense)               (None, 100)          78500       ['flatten_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 100)          0           ['dense_42[0][0]']               \n",
      "                                                                                                  \n",
      " dense_43 (Dense)               (None, 150)          15150       ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 150)          0           ['dense_43[0][0]']               \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 100)          15100       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 100)         0           ['dense_44[0][0]',               \n",
      " da)                                                              'dense_42[0][0]']               \n",
      "                                                                                                  \n",
      " dense_45 (Dense)               (None, 10)           1010        ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,760\n",
      "Trainable params: 109,760\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73649090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
