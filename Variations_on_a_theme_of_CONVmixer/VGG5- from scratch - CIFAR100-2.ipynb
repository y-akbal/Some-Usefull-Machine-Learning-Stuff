{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ee335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, dataset\n",
    "from torchvision.transforms import AutoAugment, Normalize, Compose, ToTensor\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681bf14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa44f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class accuracy:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def update(self, x,y):\n",
    "        pass\n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "046bb3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __normalize__(x):\n",
    "    return x/255.\n",
    "normalize = torch.jit.script(__normalize__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c884fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adde0a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data = CIFAR100(\"./data\", train = True, download = True, transform = Compose([AutoAugment(),ToTensor(), normalize]))\n",
    "test_data = CIFAR100(\"./data\", train = False, download = True, transform = Compose([AutoAugment(),ToTensor(),  normalize]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24c9a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DataLoader(data, 128, shuffle = True, num_workers=2)\n",
    "test_set = DataLoader(test_data, 128, shuffle = False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d055775",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq_1 = nn.Sequential(nn.Conv2d(3, 64, 2,2), nn.GELU(),                                                                     \n",
    "                                   nn.BatchNorm2d(64))\n",
    "        self.seq_2 = nn.Sequential(nn.Conv2d(64, 128, 2,1), nn.GELU(),\n",
    "                                   nn.Conv2d(128, 128, 2,1), nn.GELU(), \n",
    "                                   nn.Conv2d(128, 128, 2,1), nn.GELU(), \n",
    "                                   nn.MaxPool2d(2,2, ), \n",
    "                                   nn.BatchNorm2d(128))\n",
    "        self.seq_3 = nn.Sequential(nn.Conv2d(128, 256, 2,1, padding = \"same\"), nn.GELU(),\n",
    "                                   nn.Conv2d(256, 256, 2,1, padding = \"same\"), nn.GELU(), \n",
    "                                   nn.Conv2d(256, 256, 2,1, padding = \"same\"), nn.GELU(), \n",
    "                                   nn.MaxPool2d(2,2, padding = 1), \n",
    "                                   nn.BatchNorm2d(256, ))\n",
    "        self.seq_4 = nn.Sequential(nn.Conv2d(256, 512, 2,1, padding = \"same\"), nn.GELU(),\n",
    "                                   nn.Conv2d(512, 512, 2,1, padding = \"same\"), nn.GELU(), \n",
    "                                   nn.Conv2d(512, 512, 2,1, padding = \"same\"), nn.GELU(), \n",
    "                                   nn.MaxPool2d(2,2, padding = 1), \n",
    "                                   nn.BatchNorm2d(512, ))\n",
    "        self.seq_5 = nn.Sequential(nn.Conv2d(512, 1024, 2,1, padding = \"same\"), nn.GELU(),\n",
    "                                   nn.MaxPool2d(2,2), \n",
    "                                   nn.BatchNorm2d(512, ))\n",
    "        \n",
    "        self.f = nn.Flatten()\n",
    "        self.dense = nn.Linear(4608, 100)\n",
    "    def forward(self, x):\n",
    "        x = self.seq_1(x)\n",
    "        x = self.seq_2(x)\n",
    "        x = self.seq_3(x)\n",
    "        x = self.seq_4(x)\n",
    "        x = self.f(x)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8bd8886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VGG5(\n",
       "    (seq_1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (seq_2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (seq_3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (seq_4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (seq_5): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (f): Flatten(start_dim=1, end_dim=-1)\n",
       "    (dense): Linear(in_features=4608, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ = VGG5()\n",
    "model = torch.nn.DataParallel(model_)\n",
    "model.to(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "541c5363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sahmaran/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(1,3,32,32)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2076f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x,y):\n",
    "    return nn.CrossEntropyLoss()(model(x),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74c3dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff172a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 35.822784810126585 2.7390482486666317\n",
      "1 37.29113924050633 2.7020462595898174\n",
      "2 37.55696202531646 2.6640858863625687\n",
      "3 37.265822784810126 2.6410662347398453\n",
      "4 37.962025316455694 2.5962708209786576\n",
      "5 38.0126582278481 2.5644698960092063\n",
      "6 38.68354430379747 2.531549814107168\n",
      "7 39.0253164556962 2.5096268275814593\n",
      "8 38.34177215189873 2.4792110797999154\n",
      "9 39.50632911392405 2.449424204009268\n",
      "10 39.45569620253165 2.4229745931942444\n",
      "11 39.9746835443038 2.395432296616342\n",
      "12 40.34177215189873 2.36309408501286\n",
      "13 40.22784810126582 2.343175432871065\n",
      "14 40.9746835443038 2.318177201558867\n",
      "15 41.67088607594937 2.299811732738524\n",
      "16 41.20253164556962 2.2743758463188817\n",
      "17 41.91139240506329 2.2425808016296545\n",
      "18 41.75949367088607 2.225042687352661\n",
      "19 41.40506329113924 2.2017257326399275\n",
      "20 41.67088607594937 2.1825710242361667\n",
      "21 41.962025316455694 2.1494564692992384\n",
      "22 42.48101265822785 2.1371956533178342\n",
      "23 42.0253164556962 2.10865489570686\n",
      "24 42.721518987341774 2.0817197881391287\n",
      "25 42.91139240506329 2.078015821669108\n",
      "26 42.79746835443038 2.0564118151164728\n",
      "27 43.87341772151899 2.0310382434474232\n",
      "28 42.67088607594937 2.020334289201995\n",
      "29 43.30379746835443 1.9988744411322161\n",
      "30 42.65822784810127 1.9789300775893814\n",
      "31 43.278481012658226 1.9688236295719586\n",
      "32 43.607594936708864 1.933918960563972\n",
      "33 43.10126582278481 1.9142179604991318\n",
      "34 43.35443037974684 1.9026860440783488\n",
      "35 42.734177215189874 1.8967388920162036\n",
      "36 43.151898734177216 1.862705437728511\n",
      "37 43.0 1.8508993182950617\n",
      "38 44.379746835443036 1.8450644299807146\n",
      "39 43.22784810126582 1.821379747537091\n",
      "40 44.56962025316456 1.7958009877168308\n",
      "41 43.607594936708864 1.780689738290694\n",
      "42 43.70886075949367 1.7666140947195574\n",
      "43 45.177215189873415 1.7470325978515704\n",
      "44 44.79746835443038 1.7323428849734919\n",
      "45 44.43037974683544 1.7227976255099793\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "while True:\n",
    "    L = []\n",
    "    loss__ = []\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(train_set):\n",
    "        x, y = batch[0].cuda(), batch[1].cuda()\n",
    "    \n",
    "        loss_ = loss(x,y)\n",
    "        loss_.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss__.append(loss_.item())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "            \n",
    "        for j, batch in enumerate(test_set):\n",
    "            cond = 1\n",
    "            if cond: ### here we do reservoir sampling\n",
    "                x, y = batch[0].cuda(), batch[1].cuda()\n",
    "                L.append(sum(torch.argmax(model(x), dim = 1) == y).item())\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "    print(t, sum(L)/len(L), sum(loss__)/len(loss__))\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f4989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
