{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ee335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, dataset\n",
    "from torchvision.transforms import AutoAugment, Normalize, Compose, ToTensor\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57580d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa44f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class accuracy:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def update(self, x,y):\n",
    "        pass\n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "046bb3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __normalize__(x):\n",
    "    return x/255. -1/2    #####Normalization is different here!\n",
    "normalize = torch.jit.script(__normalize__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c884fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adde0a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data = CIFAR100(\"./data\", train = True, download = True, transform = Compose([AutoAugment(),ToTensor(), normalize]))\n",
    "test_data = CIFAR100(\"./data\", train = False, download = True, transform = Compose([ToTensor(),  normalize]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24c9a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DataLoader(data, 128, shuffle = True, num_workers=2)\n",
    "test_set = DataLoader(test_data, 128, shuffle = False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d055775",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq_1 = nn.Sequential(nn.Conv2d(3, 64, 2,2),                                                                     \n",
    "                                   nn.BatchNorm2d(64))\n",
    "        self.seq_2 = nn.Sequential(nn.Conv2d(64, 128, 2,1), nn.GELU(),\n",
    "                                   nn.MaxPool2d(2,2, ), \n",
    "                                   nn.BatchNorm2d(128))\n",
    "        self.seq_3 = nn.Sequential(nn.Conv2d(128, 256, 2,1, padding = \"same\"), nn.GELU(),\n",
    "                                   nn.MaxPool2d(2,2, padding = 1), \n",
    "                                   nn.BatchNorm2d(256, ))\n",
    "        self.seq_4 = nn.Sequential(nn.Conv2d(256, 512, 2,1, padding = \"same\"), nn.GELU(),\n",
    "                                    \n",
    "                                   nn.MaxPool2d(2,2, padding = 1), \n",
    "                                   nn.BatchNorm2d(512, ))\n",
    "        self.seq_5 = nn.Sequential(nn.Conv2d(512, 128, 2,1, padding = \"same\"), nn.GELU(),\n",
    "                                   nn.MaxPool2d(2,2), \n",
    "                                   nn.BatchNorm2d(128, ))\n",
    "        \n",
    "        self.f = nn.Flatten()\n",
    "        self.dense = nn.Linear(4608, 100)\n",
    "    def forward(self, x):\n",
    "        x = self.seq_1(x)\n",
    "        x = self.seq_2(x)\n",
    "        x = self.seq_3(x)\n",
    "        x = self.seq_4(x)\n",
    "        x = self.f(x)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8bd8886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VGG5(\n",
       "    (seq_1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (seq_2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (seq_3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (seq_4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (seq_5): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(2, 2), stride=(1, 1), padding=same)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (f): Flatten(start_dim=1, end_dim=-1)\n",
       "    (dense): Linear(in_features=4608, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ = VGG5()\n",
    "model = torch.nn.DataParallel(model_)\n",
    "model.to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a48b12f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(1,3,32,32)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2076f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x,y):\n",
    "    return nn.CrossEntropyLoss()(model(x),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74c3dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff172a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 56.68354430379747 2.088542774815084\n",
      "1 57.77215189873418 2.1051719347229394\n",
      "2 55.75949367088607 2.0889554386553555\n",
      "3 57.55696202531646 2.0969594387752015\n",
      "4 57.12658227848101 2.091485524421458\n",
      "5 56.77215189873418 2.084475754167113\n",
      "6 56.0253164556962 2.089185520511149\n",
      "7 54.075949367088604 2.087197310174518\n",
      "8 57.78481012658228 2.087963814930538\n",
      "9 57.49367088607595 2.078727123682456\n",
      "10 57.20253164556962 2.086736709870341\n",
      "11 57.78481012658228 2.08079997962698\n",
      "12 58.063291139240505 2.087153507010711\n",
      "13 57.35443037974684 2.0742868703344595\n",
      "14 57.87341772151899 2.075040643782262\n",
      "15 56.74683544303797 2.0790855344908925\n",
      "16 57.91139240506329 2.0723780103961524\n",
      "17 57.949367088607595 2.0744589777553784\n",
      "18 58.44303797468354 2.071952709456539\n",
      "19 56.87341772151899 2.081192556854404\n",
      "20 57.88607594936709 2.0761637041330947\n",
      "21 58.10126582278481 2.075338909083315\n",
      "22 57.45569620253165 2.0660709325614794\n",
      "23 57.67088607594937 2.0644180146629547\n",
      "24 57.278481012658226 2.0732933063336345\n",
      "25 57.63291139240506 2.0695225887591273\n",
      "26 55.734177215189874 2.0597627486109427\n",
      "27 53.734177215189874 2.0747641056699826\n",
      "28 54.45569620253165 2.070180100248293\n",
      "29 56.69620253164557 2.0643565325480897\n",
      "30 56.54430379746835 2.0652623944880104\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "while True:\n",
    "    L = []\n",
    "    loss__ = []\n",
    "    model.train()\n",
    "\n",
    "    for i, batch in enumerate(train_set):\n",
    "        x, y = batch[0].cuda(), batch[1].cuda()\n",
    "    \n",
    "        loss_ = loss(x,y)\n",
    "        loss_.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss__.append(loss_.item())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "            \n",
    "        for j, batch in enumerate(test_set):\n",
    "            cond = 1\n",
    "            if cond: ### here we do reservoir sampling\n",
    "                x, y = batch[0].cuda(), batch[1].cuda()\n",
    "                L.append(sum(torch.argmax(model(x), dim = 1) == y).item())\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "    print(t, sum(L)/len(L), sum(loss__)/len(loss__))\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dd60ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
