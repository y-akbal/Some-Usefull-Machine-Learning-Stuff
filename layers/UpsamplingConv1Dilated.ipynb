{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97dbd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout,Embedding, GRU, BatchNormalization, Input\n",
    "from tensorflow.keras.layers import Conv1D, Conv1DTranspose\n",
    "from tensorflow.keras.activations import relu, softmax, gelu\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.losses import mean_squared_error, categorical_crossentropy, sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Concatenate, concatenate\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96f5ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class upsample_conv(Layer):\n",
    "    def __init__(self, pool_size = 4, lags = 256, internal_dim = 128, activation = \"gelu\", dropout_rate = 0.2):\n",
    "        assert (lags/pool_size).is_integer(), \"Lag size should be divisible by pool_size\"\n",
    "        super().__init__()\n",
    "        self.conv = Conv1D(filters = internal_dim, kernel_size = pool_size, strides = pool_size, use_bias = False)\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        self.norm = BatchNormalization()\n",
    "        self.embed = Embedding(int(lags/pool_size), internal_dim)\n",
    "        self.list = np.array([i for i in range(int(lags/pool_size))])\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "    @tf.function(jit_compile = True)\n",
    "    def call(self, inputs, training = None):\n",
    "        x = self.dropout(inputs, training)\n",
    "        x = self.conv(inputs)\n",
    "        x += self.embed(self.list)\n",
    "        x = self.activation(x)\n",
    "        x = self.norm(x, training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b38f7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
